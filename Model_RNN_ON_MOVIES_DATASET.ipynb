{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pMxuTjD1Tl3v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnmmFbJkTxja",
        "outputId": "076455a3-8939-41ae-8b94-226577a8cdae"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "with open('/content/drive/MyDrive/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('/content/drive/MyDrive/labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "metadata": {
        "id": "8w6ASR62Txgh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "with open('/content/drive/MyDrive/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('/content/drive/MyDrive/labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "metadata": {
        "id": "uDeUTXci05Ll"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews[:500])\n",
        "print()\n",
        "print(labels[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFAR5XGtTxeA",
        "outputId": "c8099819-5809-4bc6-adf6-cfe1d996adda"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which\n",
            "\n",
            "positive\n",
            "negative\n",
            "po\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from string import punctuation\n",
        "\n",
        "# remove punctuation\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of all words\n",
        "all_words = all_text.split()\n"
      ],
      "metadata": {
        "id": "AUEz6F1STxbl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1=positive, 0=negative label conversion\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])"
      ],
      "metadata": {
        "id": "G654NbZ_TxZN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Build a dictionary that maps indices to review lengths\n",
        "counts = Counter(all_words)\n",
        "\n",
        "review_lens = Counter([len(x.split()) for x in reviews_split])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uucnO5HyTxWJ",
        "outputId": "3f0880f6-502b-4d07-de2f-dcd04f25905a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-length reviews: 1\n",
            "Maximum review length: 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of reviews before removing outliers: ', len(reviews_split))\n",
        "\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_split) if len(review.split()) != 0]\n",
        "\n",
        "reviews_split = [reviews_split[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eupYXtqTxTL",
        "outputId": "89f883ad-264c-421e-d6e4-6249d0bfea90"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews before removing outliers:  25001\n",
            "Number of reviews after removing outliers:  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Using a Pre-Trained Embedding Layer***"
      ],
      "metadata": {
        "id": "Rp1xHGT1Ubzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Creating the model\n",
        "embed_lookup = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300-SLIM.bin',\n",
        "                                                 binary=True)\n"
      ],
      "metadata": {
        "id": "u12BuaDGTxPl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_words = []\n",
        "for index, word in enumerate(embed_lookup.index_to_key):\n",
        "    pretrained_words.append(word)"
      ],
      "metadata": {
        "id": "ngAl7ge7TxKg"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_idx = 1\n",
        "\n",
        "# get word/embedding in that row\n",
        "word = pretrained_words[row_idx]\n",
        "embedding = embed_lookup[word]\n",
        "\n",
        "# vocab and embedding info\n",
        "print(\"Size of Vocab: {}\\n\".format(len(pretrained_words)))\n",
        "print('Word in vocab: {}\\n'.format(word))\n",
        "print('Length of embedding: {}\\n'.format(len(embedding)))\n",
        "#print('Associated embedding: \\n', embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuW3QS3bTxHY",
        "outputId": "46fbcf5c-aa9f-472c-f608-0659bed3ffdb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Vocab: 299567\n",
            "\n",
            "Word in vocab: for\n",
            "\n",
            "Length of embedding: 300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity"
      ],
      "metadata": {
        "id": "ntlmOYHsUpsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_similar_to = 'fabulous'\n",
        "\n",
        "print('Similar words to '+find_similar_to+': \\n')\n",
        "\n",
        "# Find similar words, using cosine similarity\n",
        "for similar_word in embed_lookup.similar_by_word(find_similar_to):\n",
        "    print(\"Word: {0}, Similarity: {1:.3f}\".format(\n",
        "        similar_word[0], similar_word[1]\n",
        "    ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCCcE7kbTxEh",
        "outputId": "f7440a98-48b3-44f7-b22a-424f4f86c38f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words to fabulous: \n",
            "\n",
            "Word: wonderful, Similarity: 0.761\n",
            "Word: fantastic, Similarity: 0.761\n",
            "Word: marvelous, Similarity: 0.730\n",
            "Word: gorgeous, Similarity: 0.714\n",
            "Word: lovely, Similarity: 0.713\n",
            "Word: terrific, Similarity: 0.694\n",
            "Word: amazing, Similarity: 0.693\n",
            "Word: beautiful, Similarity: 0.670\n",
            "Word: magnificent, Similarity: 0.667\n",
            "Word: splendid, Similarity: 0.645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize reviews"
      ],
      "metadata": {
        "id": "LetPf7r2UxpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_all_reviews(embed_lookup, reviews_split):\n",
        "    reviews_words = [review.split() for review in reviews_split]\n",
        "\n",
        "    tokenized_reviews = []\n",
        "    for review in reviews_words:\n",
        "        ints = []\n",
        "        for word in review:\n",
        "            try:\n",
        "                idx = embed_lookup.key_to_index[word]\n",
        "            except:\n",
        "                idx = 0\n",
        "            ints.append(idx)\n",
        "        tokenized_reviews.append(ints)\n",
        "\n",
        "    return tokenized_reviews\n"
      ],
      "metadata": {
        "id": "rVFfst9VTw8D"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = tokenize_all_reviews(embed_lookup, reviews_split)"
      ],
      "metadata": {
        "id": "cIqGBwihTw5g"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_hQzHwfTw2z",
        "outputId": "8a03b9e8-4685-4cc8-82c2-a0a292d5c656"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 137, 3, 0, 11620, 3799, 13, 1215, 10, 9, 194, 54, 12, 73, 61, 685, 41, 183, 243, 129, 12, 1663, 119, 72, 0, 9, 2989, 7334, 242, 159, 0, 453, 2, 0, 137, 1239, 19951, 3, 141, 1980, 0, 1898, 55, 3, 1663, 9, 11124, 0, 3857, 6663, 9, 20401, 295, 28, 45, 148, 157, 102, 27, 15452, 1663, 30714, 9, 65172, 0, 9, 844, 737, 47, 6585, 159, 0, 9, 668, 4365, 1003, 0, 27, 295, 56, 4365, 622, 9, 3832, 0, 43, 0, 897, 3187, 907, 0, 5396, 113, 9, 183, 4365, 1009, 3165, 10, 137, 0, 3288, 296, 10314, 4365, 6638, 213, 0, 8810, 40, 0, 116, 1663, 897, 2059, 0, 0, 137, 4365, 830, 2, 124, 2216, 0, 119, 782, 144, 2, 0, 137, 3, 330, 23046, 78, 0, 16915, 2, 13, 85275, 7451]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding sequences"
      ],
      "metadata": {
        "id": "lF534MedVCB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(tokenized_reviews, seq_length):\n",
        "    features = np.zeros((len(tokenized_reviews), seq_length), dtype=int)\n",
        "    for i, row in enumerate(tokenized_reviews):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "L4CUhbPKTw0J"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 200\n",
        "\n",
        "features = pad_features(tokenized_reviews, seq_length=seq_length)\n",
        "assert len(features)==len(tokenized_reviews), \"Features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "print(features[:10,:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQm2HcXWTwxJ",
        "outputId": "dac10659-cb81-43be-8ef6-ee5d7df908bc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [ 16483     26      0     12 106210      0   1698     22     37     24\n",
            "     432      1     72     30    275      0    303      0    162    126]\n",
            " [  1935   1326     12      0   1403     60   3921   2019      3   4809\n",
            "      36      6   3172   7184    129   7951      0   2180   6098 166268]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [    56   4365      8    270    119    756    247    159    381      0\n",
            "       9   2669      0    148  21621     13      8     40      0    124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training, Validation, and Test Data***"
      ],
      "metadata": {
        "id": "UQJlyEFKVMxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoM3Vw_RTwth",
        "outputId": "5ac71c5f-230c-4e6f-f363-cb3228511430"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(20000, 200) \n",
            "Validation set: \t(2500, 200) \n",
            "Test set: \t\t(2500, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoaders and Batching"
      ],
      "metadata": {
        "id": "x-J1yRnpVUSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# shuffling and batching data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "8ozqTmgXTwn5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66xuAT4MXN2n",
        "outputId": "6cdbf879-34ab-4e07-a70f-6349efc984f6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,  1239,   554,   196],\n",
            "        [    0,     0,     0,  ...,   119,   222,    90],\n",
            "        [    0,     0,     0,  ...,    55,    25,  1083],\n",
            "        ...,\n",
            "        [  986,  4365,     8,  ...,     0,   183,    26],\n",
            "        [18099,  4365,  2547,  ...,    40,    13,     3],\n",
            "        [    0,     0,     0,  ...,    15, 82750,   708]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
            "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "        0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Network with PyTorch"
      ],
      "metadata": {
        "id": "Jm3FOkd1Vb2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQjM67aPVcgQ",
        "outputId": "62a2f6ca-6602-495c-c1f1-b2270bf80d4c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "    super(SentimentRNN, self).__init__()\n",
        "    self.output_size = output_size;\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, embedding_dim, output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "    embeds=self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    #neww\n",
        "    lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "    out= self.dropout(lstm_out)\n",
        "    out = self.fc(out)[:, 0]\n",
        "    sig_out = self.sig(out)\n",
        "    return sig_out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "       hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "       weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "       hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "       weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "i3K204FRVje4"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(pretrained_words)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BzpcltmcA5e",
        "outputId": "b8318b9a-614e-47cd-edff-34d2b2dbd926"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(299568, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=400, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "92kdo_FkcPZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "s0C5HSxcVkKr"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoWeFpbAcaMV",
        "outputId": "8ef384ad-f60f-4bed-beec-5f6b26dfc15c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.635671... Val Loss: 0.672261\n",
            "Epoch: 1/4... Step: 200... Loss: 0.560111... Val Loss: 0.601486\n",
            "Epoch: 1/4... Step: 300... Loss: 0.559800... Val Loss: 0.581099\n",
            "Epoch: 1/4... Step: 400... Loss: 0.620388... Val Loss: 0.623393\n",
            "Epoch: 2/4... Step: 500... Loss: 0.598536... Val Loss: 0.576957\n",
            "Epoch: 2/4... Step: 600... Loss: 0.476709... Val Loss: 0.511161\n",
            "Epoch: 2/4... Step: 700... Loss: 0.386443... Val Loss: 0.457597\n",
            "Epoch: 2/4... Step: 800... Loss: 0.373941... Val Loss: 0.441280\n",
            "Epoch: 3/4... Step: 900... Loss: 0.422151... Val Loss: 0.483860\n",
            "Epoch: 3/4... Step: 1000... Loss: 0.219372... Val Loss: 0.455632\n",
            "Epoch: 3/4... Step: 1100... Loss: 0.392883... Val Loss: 0.477250\n",
            "Epoch: 3/4... Step: 1200... Loss: 0.462948... Val Loss: 0.446629\n",
            "Epoch: 4/4... Step: 1300... Loss: 0.238527... Val Loss: 0.488366\n",
            "Epoch: 4/4... Step: 1400... Loss: 0.155791... Val Loss: 0.468464\n",
            "Epoch: 4/4... Step: 1500... Loss: 0.350579... Val Loss: 0.482890\n",
            "Epoch: 4/4... Step: 1600... Loss: 0.315173... Val Loss: 0.450583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "XS05UtHWd38l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "# Replace net3 with net\n",
        "net.eval()\n",
        "# Initialize hidden state before the loop\n",
        "h = net.init_hidden(batch_size)\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Creating new variables for the hidden state\n",
        "    h = tuple([each.data for each in h])\n",
        "    # Replace net3 with net and pass hidden state\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "ywBrvDaXe3bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c6fde6-16bf-46a5-ab91-90413edaab50"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.438\n",
            "Test accuracy: 0.812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference on a test review"
      ],
      "metadata": {
        "id": "9jMfP8F6d-qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'"
      ],
      "metadata": {
        "id": "1qUvXYZRnHHy"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower()\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # Create vocab_to_int if it doesn't exist\n",
        "    global vocab_to_int # Declare vocab_to_int as global to modify it\n",
        "    if 'vocab_to_int' not in globals():\n",
        "        vocab_to_int = {word: index for index, word in enumerate(pretrained_words)}\n",
        "\n",
        "    test_ints = [vocab_to_int.get(word, 0) for word in test_words] # Correct get usage\n",
        "    return test_ints # Return the tokenized review\n",
        "\n"
      ],
      "metadata": {
        "id": "qOJoomOhKsmu"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test sequence padding\n",
        "seq_length= 200\n",
        "test_inits = [tokenize_review(test_review_neg)] # Assign the tokenized review to test_inits\n",
        "feature = pad_features(test_inits,seq_length) # Now test_inits is defined\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qilf9SIK-yQ",
        "outputId": "24feeb23-ca03-46a9-ba1a-39be1ded435a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0 ...    13 85275  7451]\n",
            " [    0     0     0 ...    14   441  4699]\n",
            " [16483    26     0 ...   726     6     0]\n",
            " ...\n",
            " [   73  2419     2 ...   716    36   117]\n",
            " [    0     0     0 ...    61   125    15]\n",
            " [    0     0     0 ...    25     3  5635]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test conversion to tensor and pass into your model\n",
        "feature_tesnsor = torch.from_numpy(feature)\n",
        "print(feature_tesnsor.size())"
      ],
      "metadata": {
        "id": "cDcwwerhpN-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d37907-d28c-4dfa-c258-546187fc9cac"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "\n",
        "\n",
        "    net3.eval()\n",
        "    print(test_review)\n",
        "    test_ints = tokenize_review(embed_lookup, test_review)\n",
        "\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features([test_ints], seq_length)\n",
        "\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    output = net3(feature_tensor)\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")"
      ],
      "metadata": {
        "id": "V96cPUnBljfL"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict (net, test_review, sequence_length=200):\n",
        "  net.eval()\n",
        "  # tikenize rewiew\n",
        "  test_ints = tokenize_review( test_review)\n",
        "\n",
        "  seq_length=sequence_length\n",
        "  features = pad_features([test_ints], seq_length)\n",
        "  feature_tensor = torch.from_numpy(features)\n",
        "  batch_size = feature_tensor.size(0)\n",
        "  h = net.init_hidden(batch_size)\n",
        "  if(train_on_gpu):\n",
        "    feature_tensor = feature_tensor.cuda()\n",
        "  output, h = net(feature_tensor, h)\n",
        "  pred = torch.round(output.squeeze())\n",
        "  print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "  if(pred.item()==1):\n",
        "    print(\"Positive review detected!\")\n",
        "  else:\n",
        "    print(\"Negative review detected.\")"
      ],
      "metadata": {
        "id": "2pZIylBbljRk"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positive test review\n",
        "test_review_pos = 'This movie had the best acting and the dialogue was so great. I loved it!'"
      ],
      "metadata": {
        "id": "fy2UgocNsK4Y"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call function\n",
        "seq_length=200\n",
        "predict(net, test_review_pos, seq_length)"
      ],
      "metadata": {
        "id": "EcBL9bsjsKiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1db9b6-f48f-4f2a-ba0c-35a0d12c972f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.991529\n",
            "Positive review detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on pos/neg reviews"
      ],
      "metadata": {
        "id": "v-Qx6TkPeIDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=200"
      ],
      "metadata": {
        "id": "aW07-qpWeFmE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_review_pos = 'This movie had the best acting and the dialogue was so great. I loved it.'\n",
        "\n",
        "predict( net, test_review_pos, seq_length)"
      ],
      "metadata": {
        "id": "NiIJQIveeFfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f2abfc-3b5f-4da7-8610-331f20a66533"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.991529\n",
            "Positive review detected!\n"
          ]
        }
      ]
    }
  ]
}